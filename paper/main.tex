\documentclass[acmsmall, screen]{acmart}
\setlength{\pdfpagewidth}{8.5in}
\setlength{\pdfpageheight}{11in}



%%% The following is specific to OOPSLA '21 and the paper
%%% 'Why We Eval in the Shadows'
%%% by Aviral Goel, Pierre Donat-Bouillud, Filip Křikava, Christoph M. Kirsch, and Jan Vitek.
%%%
%\setcopyright{ACMUNKNOWN} %TODO: we still have to choose the copyright
\acmPrice{}
\acmDOI{10.1145/3485502}
\acmYear{2021}
\copyrightyear{2021}
\acmSubmissionID{oopsla21main-p121-p}
\acmJournal{PACMPL}
\acmVolume{5}
\acmNumber{OOPSLA}
\acmArticle{125}
\acmMonth{10}


\bibliographystyle{ACM-Reference-Format}
\citestyle{acmauthoryear}   %% For author/year citations
\usepackage{listings,hyperref,multirow,paralist,xspace,url,wrapfig,tikz}
\usetikzlibrary{positioning,automata,fit,shapes.geometric,backgrounds,calc}
\usepackage{tabularx}
\input{macro}
\newcommand{\NOTE}[1]{{\it Note: #1}\xspace}
\newcommand{\authorcomment}[3]{\xspace\textcolor{#1}{{\bf #2} #3}\xspace}
\newcommand{\todo}[1]{\authorcomment{red}{TODO}{#1}}
\renewcommand{\k}[1]{\lstinline |#1|\xspace}
% cf. https://tex.stackexchange.com/a/144640
\makeatletter\let\expandableinput\@@input\makeatother
\lstdefinelanguage{smalleR} {
  keywords={
    for,
    if,
    else,
    function,
    break,
    in
  },
  sensitive=true, % keywords are case-sensitive
  morecomment=[l]{\#}, % l is for line comment
  morestring=[b]{"} % defines that strings are enclosed in double quotes
}
\lstset{
  language={smalleR},
  columns=flexible,
  captionpos=b,
  frame=single,
  framerule=0pt,
%  framexleftmargin=1mm,
%  framexrightmargin=1mm,
  tabsize=2,
  belowskip=0pt,
  basicstyle=\small\ttfamily,
  backgroundcolor=\color{LightGray},
  emphstyle=\sffamily,
  keywordstyle=\bfseries,
  commentstyle=\color{Gray}\em,
  stringstyle=\color{Gray},
  showspaces=false,
  showstringspaces=false,
  deletekeywords={see_if, $, _, .},
  % alsoletter={., _, $},
  %emph={eval.parent, evalq, eval, local},
  %emphstyle=\underbar,
  breaklines=true
}

\usepackage{caption}


\begin{document}
\title{What We Eval in the Shadows}
\subtitle{A Large-scale Study of Eval in R programs}


%%% TODO CHANGE
\keywords{eval, dynamic languages}
\begin{CCSXML}
	<ccs2012>
	<concept>
	<concept_id>10011007.10011006.10011008.10011024</concept_id>
	<concept_desc>Software and its engineering~Language features</concept_desc>
	<concept_significance>500</concept_significance>
	</concept>
	<concept>
	<concept_id>10011007.10011006.10011008</concept_id>
	<concept_desc>Software and its engineering~General programming languages</concept_desc>
	<concept_significance>300</concept_significance>
	</concept>
	<concept>
	<concept_id>10011007.10011006.10011041.10011044</concept_id>
	<concept_desc>Software and its engineering~Just-in-time compilers</concept_desc>
	<concept_significance>300</concept_significance>
	</concept>
	<concept>
	<concept_id>10011007.10011006.10011008.10011009.10011021</concept_id>
	<concept_desc>Software and its engineering~Multiparadigm languages</concept_desc>
	<concept_significance>100</concept_significance>
	</concept>
	</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~Language features}
\ccsdesc[300]{Software and its engineering~General programming languages}


\author{Aviral Goel}\affiliation{\institution{Northeastern
    University}\country{USA}}
\author{Pierre Donat-Bouillud}\affiliation{\institution{Czech Technical University in Prague}\country{Czech Republic}}
\author{Filip Křikava}\affiliation{\institution{Czech Technical University in Prague}\country{Czech Republic}}
\author{Christoph M.~Kirsch}\affiliation{\institution{University of Salzburg}\country{Austria}}
\affiliation{\institution{Czech Technical University in Prague}\country{Czech Republic}}
\author{Jan Vitek}\affiliation{\institution{Northeastern University}\country{USA}}
\affiliation{\institution{Czech Technical University in Prague}\country{Czech Republic}}

\begin{abstract}
  Most dynamic languages allow users to turn text into code using various
  functions, often named \eval, with language-dependent semantics. The
  widespread use of these reflective functions hinders static analysis and
  prevents compilers from performing optimizations. This paper aims to provide a
  better sense of why programmers use \eval. Understanding why \eval is used in
  practice is key to finding ways to mitigate its negative impact. We have
  reasons to believe that reflective feature usage is language and application
  domain-specific; we focus on data science code written in R and compare our
  results to previous work that analyzed web programming in JavaScript. We
  analyze \packageAllcalls calls to \eval from \CranRunnableScripts scripts
  extracted from \CranPackages R packages. We find that \eval is indeed in
  widespread use; R's \eval is more pervasive and arguably dangerous than what
  was previously reported for JavaScript.
\end{abstract}

\maketitle
\renewcommand{\shortauthors}{Goel et al.}
\renewcommand{\shorttitle}{What We Eval in the Shadows}

\section{Introduction}

Most dynamic languages provide their users with a facility to transform
unstructured text into executable code and evaluate that code. We refer to this
reflective facility as \eval bowing to its origins in LISP, all the way back in
1956. \Eval has been much maligned over the years. In computing lore, it is as
close to a boogeyman as it gets. Yet, for \citet{lisp}, \eval was simply the way to
write down the definition of LISP; he was surprised that someone coded it up and
offered it to end-users. Since then, reflective facilities have been
used to parameterize programs over code patterns that can be provided after the
program is written. The presence of such a feature in a language is a hallmark
of dynamism; it is a form of delayed binding as the behavior of any particular
call to \eval will only be known when the program is run, and that particular
call site is evaluated.

\paragraph{Trouble in Paradise.} Reflective facilities hinder
most attempts to reason about or apply meaning-preserving transformations to the
code using them. In practice, \eval causes static analysis techniques to lose so
much precision as to become pointless. For compilers, anything but the most
trivial, local optimizations are unsound after the use of \eval. Furthermore,
the addition of arbitrary code --- code that could have been obtained from a
network connection --- as a program is running is a security vulnerability
waiting to happen. To illustrate these challenges, consider the interaction of a
static analysis tool with a dynamic language. A program analyzer computes an
over-approximation of the set of possible behaviors exhibited by the program
under study, a reflective facility must be represented by all behaviors that can
be expressed in the target language. \ie any legal sequence of instructions can
replace \eval. As dynamic languages are permissive, the tool must assume that
all functions in scope were redefined, \eg that \texttt{`+`} now opens a network
connection. A single occurrence of \eval causes the static analyzer to lose all
information about the program state and meaning of identifiers. This loss of
precision can sometimes be mitigated by analyzing the string
argument~\cite{moller03}, but if the string comes from outside the program, not
much can be done. A frustrated group of researchers argued giving up on
soundness and, instead, under-approximating dynamic features~\cite{soundy}. In
their words, ``a practical analysis, may pretend that \eval does nothing unless
it can precisely resolve its string argument at compile time.'' Alas, assuming
that \eval does not have side-effects or that side-effects will not affect
results is unduly optimistic.

\paragraph{Is Past Prologue?} Previous work investigated
\eval in web programming, specifically JavaScript web pages~\cite{pldi10a}. In
2011, 82\% of the 10,000 most accessed sites used \eval~\cite{ecoop11}. Yet, the
strings passed to \eval, and their behaviors, when executed, were far from
random; it was shown that when one could observe several calls, the ``shape'' of
future calls could be predicted with 97\% accuracy~\cite{oopsla12b}. Overall,
practical usage suggested that most reflective calls were relatively harmless.
While this backed up the soundiness squad's approach, does it generalize to
other application domains and to other languages?

\paragraph{The Here and Now.} In this study, we investigate the usage of \eval
in programs written in the R language. R is a language designed by statisticians
for applications in data science~\cite{r}. What makes looking at R after
JavaScript interesting is that, while both languages are dynamic, they are quite
different. While one can program in an object-oriented style in R like in
JavaScript, R is mostly a lazy functional language. JavaScript was designed to
run untrusted code in a browser, while R is used for statistical computing on
desktops. JavaScript is a general-purpose language used by a vast community of
programmers, while R is used for scientific computing by data scientists and
domain experts with, often, limited programming experience. One can distinguish
between library implementers who have programming experience and a working
knowledge of R, and end-users who are typically not expert programmers with a
cursory knowledge of the language. Our goal is to highlight the
differences in usage between JavaScript and R and explain them in terms of
language features, application domain, and programmer experience. Hopefully,
some of our observations generalize to other languages.

\paragraph{The What and How.} One benefit of
R is that every package in the CRAN repository comes with examples of typical
usage. This gives us a codebase that we can analyze dynamically. To observe
\eval, we built a two-level monitoring infrastructure: we monitor programs by
instrumentation and we also monitor the inner workings of the interpreter.
Dynamic analysis is limited as it can only observe behaviors triggered by the
particular inputs passed to a program. Luckily, R libraries come with many tests
and use-cases. Our corpus is constructed to reflect the levels of sophistication
of the R community. We distinguish between \emph{CRAN packages} (\CranPackages
curated packages that pass quality checks and have tests and sample data) and
\emph{Kaggle scripts} (\KaggleUnique end-user written programs) It is reasonable
to expect \eval usage to differ between these datasets, libraries are part of a
lively and growing ecosystem, while end-user code is often thrown together, run
once, and never revisited.


\paragraph{Why do we Eval?} The results of our study suggest
that \eval is widely used for the implementation of the language, and in many
libraries. End-user code makes less frequent and less sophisticated use of
\eval. In many ways, \eval in R is as bad as it gets: it's varied, performs
side-effects, and reaches many environments. By large, the motivations for
\eval relate to various forms of language extensions and meta-programming. \Eval
is used where other languages would provide macros. But, the expressive power of
\eval is higher as it can reach arbitrarily far back in the call stack.

\medskip

Our data and code are
open-source and publicly available at:

\begin{center}
  \url{https://doi.org/10.5281/zenodo.5415230}
\end{center}



\section{Background and Previous work}

This section provides a short introduction to R and the reflective features of
the language; then looks at the semantics of \eval in R and discusses design
choices; lastly, this work is put in context.

\subsection{R, Briefly}

\citet{ecoop12} give a programming language-centric overview of the R language.
They characterized it as a lazy, vectorized, functional language with a rich
complement of dynamic features expressive enough to layer several object systems
on top of the core language. Most data types are sequences of primitive values.
For instance, \k{c("Ha","bye")} evaluates to a vector of two strings. Constants
such as \k{42} are vectors of length one. To enable equational reasoning, values
accessible through multiple aliases are copied when written to. Furthermore,
values can be tagged by attributes; these are key-value pairs. For instance, the
attribute \k{dim}-\k{c(2,2)} can be attached to the value bound to \k{x} by
\k{attr(x,"dim") <- c(2,2)}. Adding this attribute turns \k{x} into a matrix.
The \k{class} attribute gives a value a 'class' in the object-oriented sense.
So, \k{class(x)<-"human"} sets the class of \k{x} to \k{human}; classes are used
for method dispatch. Every linguistic construct is desugared to a function call,
even control flow statements, assignments, and bracketing. All functions can be
shadowed and redefined, making R at the same time remarkably flexible and
exceedingly challenging to compile as vividly detailed by~\citet{dls19}. R uses
a relaxed call-by-need convention for passing arguments to functions, studied in
depth by~\citet{oopsla19b}. Each argument is a thunk composed of an expression,
its environment, and a slot for the result; these are called \emph{promises}. To
get the value of an argument, the corresponding promise must be forced. Once
forced, the promise's result is cached for future use.

\subsection{On the Expressive Power of Eval}

While a data-to-code facility is available in many languages, some design
choices affect its expressive power. The key choices are the input format, the
environment in which generated code evaluates, and the reflective operations
available to that code. Table~\ref{comp} summarizes a few designs.

\begin{table}[!h]\center\small\begin{tabular}{r@{~}llll}\toprule
\tiny\sc Language&&\sc\tiny Input&\sc\tiny Scope&\tiny\sc Reflective operations\\\midrule
\bf Julia&\cite{julia}     & expression& toplevel         & data\\
\bf Java&\cite{cl}  & bytecode  & classloader       & data\\
\bf JavaScript&\cite{ecoop11}& text      & current, toplevel& data\\
\bf R&\cite{R96}  & expression& programmatic      & data, stack, environment\\\bottomrule
\end{tabular}\caption{Design space of \eval}\label{comp}
\end{table}

The input to \eval can be in any format convertible to code. JavaScript allows
arbitrary strings; Julia and R are more restrictive as they require expressions
(or abstract syntax trees). Finally, Java is the most restrictive as its
classloader only accepts complete classes in bytecode format. These differences
mostly affect users who seem more comfortable crafting strings.

The choice of the environment of \eval is essential as it determines how much of
a program \eval can observe as well as the reach of potential side-effects
performed by its execution. The most restrictive semantics is that of Java,
where newly loaded code evaluates in the environment consisting of the classes
visible from the current classloader. Julia limits \eval to the symbols visible
in the global environment, so does JavaScript's strict mode. Finally, R is the most
flexible as any accessible environment can be selected and passed to \eval. The
choice of the environment is fully under the programmer's control.

The last degree of freedom is the expressive power of the code executed by
\eval. The main difference between languages lies in how much of the state of a
program is accessible through reflective operations. Julia, Java and, JavaScript
allow some form of introspection on the data that is visible in the environment
in which \eval executes. R is more flexible as it lets \eval inspect the program's
call stack as well as the code of any function. Thus, any environment and any
binding in contains can be inspected and modified.

Given the above, the claim that R is amongst the languages with the most
powerful \eval seems plausible. The rationale for R's design seems to have been
to expose as much of the language and its internals as possible in order to
maximize expressivity. In R, \eval is a key tool to extend the language and
implement DSLs; it is also a replacement for macros. By contrast, the designers
of Julia chose to limit \eval. In Julia, only global variables can be
side-effected, and environments cannot be readily manipulated. This is designed
to shield optimized code from some of the most pernicious uses of the
facility~\cite{oopsla18a}. Furthermore, Julia provides a versioning mechanism to
ensure that any method defined within an \eval only becomes visible at
well-defined points and thus that optimized code does not have to be
invalidated~\cite{oopsla20a}.

\begin{figure}[!t]
\begin{minipage}{.49\textwidth}
\begin{lstlisting}[caption={Examples of calls producing expression \k{a+b}},label=lst:exprs]
  parse(text="a+b")
  quote(a+b)
  call("+", quote(a), quote(b))

  # reflect promise
  f <- function(x) substitute(x)
  f(a+b)
  \end{lstlisting}
\end{minipage}
\begin{minipage}{.49\textwidth}
  \begin{lstlisting}[caption={Example of a call reflection},label=lst:match.call]
  f <- function(x, y) {
    mc <- match.call() # reflect curr. call
    mc[[1]] <- as.name("g")
    mc[["x"]] <- 3
    mc
  }
  f(1,2) # returns an expr g(x=3,y=2)
  \end{lstlisting}
\end{minipage}
\end{figure}

\subsection{Eval in R}\label{sec:eval-in-r}

The \eval function in R takes three parameters: an expression to evaluate
(\k{e}), an environment where to evaluate (\k{env}), and an enclosure (\k{encl})
that is used to look up objects not found in \k{env}.\footnote{R offers three
other variants of {\tt eval}: {\tt evalq} automatically quotes passed
expression---shorthand for {\tt eval(quote(...))}, {\tt eval.parent(e,n)}
specifies the evaluating environment in terms of number of call frames ({\tt n})
to go back---shorthand for {\tt eval(e,parent.frame(n))}, and {\tt local}
evaluates {\tt e} in a fresh environment---shorthand for {\tt
  evalq(e,new.env())}.}

\begin{lstlisting}
 eval <- function(e, env = parent.frame(),
                   encl = if(is.list(env)) parent.frame() else baseenv()) ...
\end{lstlisting}

The expression passed to \eval can be thought of as an abstract syntax tree.
Listings~\ref{lst:exprs} and \ref{lst:match.call} show some of the ways of
creating expressions: parsing from a string, manually, or via reflection. The
call to \k{substitute(x)} extracts the unevaluated expression from the promise
\k{x}. The call to \k{match.call()} returns an expression representing the
current call which can then be further modified.


R is permissive in terms of what is considered an environment. Besides
environments, it accepts lists, data frames (using element names or column names
for variable resolution), or an integer \k{n} (in which case it would use the
\k{n.} call frame). The default is the environment where the call to \eval was
made.
%
Environments nest, each has a parent. A new environment created with \k{new.env}
has the current environment as parent. Parent chains can be traversed with
\k{parent.env}, until \k{emptyenv} is reached. The top-level environment is
\k{.GlobalEnv}, its parents are the packages that have been loaded. Environments
are used as hash maps as they have reference semantics and a built-in string
lookup. One can also directly read, modify or create new bindings, given any
environment:
%
\begin{figure}[H]
\begin{minipage}{.49\textwidth}
  \begin{lstlisting}
  # reading
  envir$v
  get("v", envir=envir)
  \end{lstlisting}
\end{minipage}
\begin{minipage}{.49\textwidth}
  \begin{lstlisting}
  # writing
  envir$v <- 2
  assign("v", 2, envir=envir)
  \end{lstlisting}
\end{minipage}
\end{figure}
%

\subsection{Previous Work}

\citet{ecoop11} provided the first study at scale of the behavior of \eval in
JavaScript. A corpus of 10,000 popular websites was analyzed with an
instrumented web browser to gather execution traces. Of those sites, 82\% used
\eval for purposes such as on-demand code loading, deserialization of JSON data,
or lightweight meta-programming to customize web pages. While many uses were
legitimate, just as many were unnecessary and could be replaced with equivalent
and safer code. The authors categorized inputs to \eval. For inputs in
which all named variables refer to the global scope, many patterns could be
replaced by more disciplined code~\cite{oopsla12b, moller12}. The work did not
measure code coverage, so the numbers presented are a lower bound on possible
behaviors. Furthermore, JavaScript usage in 2011 is likely different from today,
\eg Node.js was not covered. More details about the dynamic analysis of JavaScript
can be found in~\cite{liang}.

\citet{wang} analyzed the use of dynamic features in 18 Python programs to find if
they affect file change-proneness. Files with dynamic features are significantly
more likely to be the subject of changes than other files. Chen et al. looked
at the correlation between code changes and dynamic features, including \eval,
in 17 Python programs~\cite{chen}. They did not observe many uses of \eval.
\citet{oscar} performed an empirical study of the usage of dynamic features in
1,000 Smalltalk projects. While \eval itself is not present, Smalltalk has a
rich reflective interface. The authors found that reflective methods are used in less
than 2\% of methods. The most common reflective method is \k{perform:}; it send
a message that is specified by a string. These features are primarily used in the
core libraries.

\citet{bodden} looked at the usage of reflection in the Java DaCapo benchmark suite.
They found that dynamic loading was triggered by the benchmark harness. The
harness then executes methods via reflection. This caused static analysis tools
to generate an incorrect call graph for the programs in DaCapo.

\citet{Arceri21} studied \eval in JavaScript from a software security point of
view. The authors reported that 53\% of the malware they studied used \eval as a
means to obfuscate attack code or mount attacks. They proposed an abstract
interpretation-based approach to analyzing dynamic languages. One must construct
a static approximation of the argument to \eval and then analyze possible
behaviors of the interpreter when evaluating the generated code.

\citet{ecoop12} in their evaluation of the design of the R language, briefly
looked at the use of \eval in their corpus (1763 packages). They found 8500
\eval call sites and recorded 2M \eval calls. Because they included the base
libraries, their results were dominated by a few functions with
\k{match.arg}\footnote{A base function that matches an argument against a set of
candidate values, it uses \eval to get the candidate values.} being responsible
for over half of the recorded \eval calls. They discussed two use cases. The
first one is the evaluation of an expression extracted from a promise using the
\k{substitute} call in a new environment. The other is the invocation of a
function with dynamically computed names and arguments.

In this work, we significantly expand that study. First, our corpus covers
\CranPackages packages (about the whole of CRAN at the time of writing) with
\PkgHitEvalCallSites \eval call sites, and \packageAllcallsRnd \eval calls.
Next, we track a lot more information such as the shapes of expressions passed
to \eval, their provenance, complexity, and side effects. This enables us to
have an accurate and detailed picture of the use of \eval in the R ecosystem. We
use this to provide both quantitative and qualitative views on \eval, including
several use cases to demonstrate the popularity, diversity and powerfulness of
\eval in R.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Methodology}

This section describes how the corpus of R program was selected and the analysis
infrastructure.

\subsection{Corpus}

We distinguish three sources for calls to \eval, those originating from
\emph{Base} libraries bundled with R, packages hosted on \emph{CRAN}, and
end-user scripts from \emph{Kaggle}:

\begin{itemize}[$-$]

\item \emph{Base.} The \BasePackages base libraries provide arithmetics,
  statistics, and operating system functionalities. Base has \BaseFunsWithEvals
  functions with \BaseEvalCallSites calls to \eval. These functions perform key
  tasks such as package loading, there is thus hardly any R program that does
  not invoke them. We consider base libraries as part of the language
  implementation and do not include them in our analysis.

\item \emph{CRAN.} Packages hosted on the Comprehensive R Archive Network
  ({\small \url{cran.r-project.org}}, aka CRAN) have three sources of runnable code:
  unit \emph{tests} for individual functions, code \emph{examples} embedded in
  the documentation, and use-cases called \emph{vignettes}. All runnable
  snippets can be extracted into independent files. We download \CranPackages
  packages and extract \CranRunnableScripts scripts with \CranRunnableCode
  lines of code (\CranRunnableCodeExamplesRnd in examples,
  \CranRunnableCodeVignettesRnd in vignettes and \CranRunnableCodeTestsRnd in
  tests). CRAN packages contain 20 years of contribution from
  thousands of authors, often experienced R developers.

\item \emph{Kaggle.} Kaggle ({\small \url{kaggle.com}}) is an online platform
  that allows users to submit and compete to solve problems. We download
  \KaggleUnique unique scripts and notebooks with their input files
  (\KaggleDuplicates duplicates were removed using SHA-1 hashes); 665K lines of
  R code making only \KaggleWithEvals calls \eval. The authors of these scripts
  have highly variable levels of expertise.

\end{itemize}


\paragraph{Discussion.} When we started this project, our goal was to contrast the
usage of \eval by package developers and end-users, but the Kaggle dataset has
so few calls to \eval that there is little that can be said about those. The
remainder of the paper focuses on CRAN with a few observations about the other
sources when relevant.


\subsection{Pipeline}

We implemented an automated pipeline that acquires packages, extracts scripts,
executes them, traces their behavior, and summarizes observations.
Figure~\ref{fig:pipeline} shows the main steps along with their running time,
data size, and the number of elements manipulated. The pipeline steps are:

 \begin{figure}[ht!]
   \centering
   \scalebox{0.85}{
     \begin{tikzpicture}
       \definecolor{red}{HTML}{F8CECC}
       \definecolor{darkred}{HTML}{B85450}
       \definecolor{yellow}{HTML}{FFF2CC}
       \definecolor{darkyellow}{HTML}{D6B656}
       \definecolor{blue}{HTML}{DAE8FC}
       \definecolor{darkblue}{HTML}{6C8EBF}
       \definecolor{green}{HTML}{D5E8D4}
       \definecolor{darkgreen}{HTML}{82B366}
       \newcommand{\nodesep}[0]{0.035 \textwidth}
       \newcommand{\textsep}[0]{0.005 \textwidth}
       \newcommand{\nodename}[1]{\begin{tabular}{c}#1\end{tabular}}
       \newcommand{\nodedesc}[1]{\begin{tabular}{c}#1\end{tabular}}
       \tikzstyle{block}     = [rectangle, rounded corners, minimum width=0.15 \textwidth, minimum height=60pt]
       \tikzstyle{connector} = [line width=0.25mm, ->]

       \node [block, fill = red, draw = darkred, very thick] (download) {
         \nodename{
           \vspace{1mm}\textbf{Download}\vspace{1mm}\\
           15K packages\\
           8K Kaggle kernels\\
           219 Kaggle datasets
         }
       };
       \node [below = \textsep of download]   (downloaddesc)   {\nodedesc{12 hours}};
       \node [block, right = \nodesep of download, fill = yellow, draw = darkyellow, very thick] (extract) {
         \nodename{
           \vspace{1mm}\textbf{Extract}\vspace{1mm}\\
           240K package programs\\%, 4.6M LOC\\
           74 Kaggle kernels\\%, 13K LOC\\
           \newline
         }
       };
       \node [below = \textsep of extract]   (extractdesc)   {\nodedesc{2 hours}};
       \node [block, right = \nodesep of extract, fill = blue, draw = darkblue, very thick] (trace) {
         \nodename{
           \vspace{1mm}\textbf{Trace}\vspace{1mm}\\
           49M eval calls \\
           14M side-effects\\
           \newline
         }
       };
       \node [below = \textsep of trace]     (tracedesc)     {\nodedesc{36 hours}};
       \node [block, right = \nodesep of trace, fill = green, draw = darkgreen, very thick] (analyze) {
         \nodename{
           \vspace{1mm}\textbf{Analyze}\vspace{1mm}\\
           2.8M unique eval calls\\
           22\% packages use eval\\
           \newline
         }
       };
       \node [below = \textsep of analyze]    (analyzedesc)    {\nodedesc{2 hours}};
       \draw [connector] (download)   edge (extract);
       \draw [connector] (extract)    edge (trace);
       \draw [connector] (trace)      edge (analyze);
     \end{tikzpicture}
   }
   \caption{Pipeline}\label{fig:pipeline}
 \end{figure}

\begin{compactenum}[(1)]
\item \emph{Download.} Packages are downloaded from CRAN, for Kaggle a web
  crawler retrieves code, and a command-line tool gets data. Installation is
  complicated by native dependencies which sometimes have to be resolved
  manually.
\item \emph{Extract.} The \genthat tool extracts all runnable code snippets and
  turns each of these into a self-standing program~\cite{issta18}, \k{knitr}
  extracts code from notebooks. Each extracted script is instrumented with calls
  to our dynamic analyzer in a way that avoids recording calls to \eval
  originating from our execution harness.
\item \emph{Trace.} Scripts are run with a modified R interpreter to capture
  calls to \eval in CRAN packages. Each script is run in its own process with
  the GNU R compiler turned off to avoid recording its execution.
\item \emph{Analyze.} Analysis outputs are merged, cleaned, and summarized.
  RMarkdown~\cite{rmarkdown} notebooks process the summarized data to generate all graphs (using
  \k{ggplot2}~\cite{ggplot}) and numbers (exported as \LaTeX\xspace macros)
  appearing in the paper.
\end{compactenum}

\medskip The pipeline runs in parallel~\cite{GNUparallel} orchestrated by a
Makefile. Servers have identical environments thanks to a docker image with all
dependencies installed.

\subsection{Dynamic Analysis}

The tracer that performs dynamic analysis of R scripts is built on top of
\rdyntrace, an extended R 4.0.2 virtual machine that exposes callbacks for
various runtime events~\cite{oopsla19b}. The tracer registers callbacks to all
variants of \eval and a few additional functions to locate the origin of \eval
arguments. It captures dynamic code loading, as well as variable definition and
assignment, allowing us to record side effects that happen in environments while
evaluating code in \eval. A challenge was the lack of source code references for
expressions that are not within a block surrounded by braces. This is
unfortunately not easily fixed. We extend our dynamic analysis tool to attach
synthetic source code references to all \eval call sites, but the approach fails
in some edge cases. For performance reasons, the tracer is an R package written
in C++ (3.2K LOC) and R (1.3K LOC). While in theory, the implementation should
be straightforward, it is not so in practice. Lazy evaluation requires delaying
the processing of arguments until (and if) they are forced. Accounting for
side-effects performed in an \eval is complicated by the fact that R is
implemented in a mixture of R and C, and that the language implementation can
(and does) call \eval. Lastly, large codebases exercise many edge cases of the
highly underspecified R behavior.

\paragraph{Limitations.} Even with the extension described above, there are
\PkgUndefinedRnd \eval calls without source information (\PkgUndefinedRatio of
all \eval calls). This happens when \eval is an argument to a higher-order
function or when it is called from native code. Another limitation is that we do
not record calls to the native \eval. Neither of these limitations should
invalidate our conclusions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Measuring Eval}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This section reports on the frequency of \eval in CRAN. We use \emph{site} to
refer to an occurrence of a call site to the \eval function in the source code
and \emph{call} to denote an observed invocation of the \eval function.

\begin{wrapfigure}{r}{7cm}
	\hspace*{-1cm}\includegraphics[width=9cm]{pkgs-eval-callsites-hist.pdf}
	\caption{ \eval call sites}\label{fig:pkgs-eval-callsites-hist}
\end{wrapfigure}

There are \PkgEvalCallSites \eval sites in \PkgPackages packages;
\PkgPackagesRatio packages use \eval. Over half of these packages have fewer
than 3 sites, and with the exception \MaxEvalCallSitesPackage which has
\MaxEvalCallSitesCount sites, all packages contain fewer than
\MaxEvalCallSitesRest sites. Fig~\ref{fig:pkgs-eval-callsites-hist} shows a
histogram of sites per package. Sites appear in \PkgFunsWithEval functions;
\CranFunsWithEvalRatio of all functions use \eval.



Our pipeline runs \CranRunnableScripts scripts extracted from \CranPackages
packages. Any run that does not call \eval is discarded, leaving us with
\packageNbruns runs. In these runs, \packageAllcalls \eval calls were recorded
originating from \PkgHitEvalCallSites sites. The runs exercised
\PkgHitEvalCallSitesAvgRatio of sites, a ratio similar to the package code
coverage metric which is \PkgCodeCoverage. The reasons some sites are not
exercised can be chalked down to incomplete tests and analysis failures
(\PkgFailedProgramsRatio of the runs crashed or timed out).
Fig.~\ref{fig:traced-eval-callsites} plots exercised sites with respect to all
sites for each program; as can be seen, coverage is unequal.
Table~\ref{tab:freq} summarizes the frequency of calls, call counts on the left, and
number of packages on the right. There are \packageFewcalls packages with fewer
than 100 calls, and \packageManycalls packages with more than 1,000 calls.
\packageMaxcallspack calls \eval \packageMaxcalls times and thus accounts for
over half of our observations.

\begin{table}[H]
\centering
\small
\begin{tabular}{@{}l@{\hspace{1.5cm}}l@{}}
\begin{minipage} {5cm}\small
  \begin{tabular}{r@{\,}r@{\,}l@{}r|r@{\,}r@{\,}l@{}r@{}} \toprule
    \multicolumn{3}{c}{\bf \small\#calls} &\bf \small \#pck
&     \multicolumn{3}{c}{\bf \small\#calls} &\bf \small\#pck \\\midrule
\tt 1 &--& \tt 10      & \packageBina  & \tt 10K &--&\tt 100K  & \packageBine\\
\tt 11 &--& \tt 100    & \packageBinb  & \tt 100K &--&\tt 1M  & \packageBinf\\
\tt 101 &--& \tt 1K    & \packageBinc  & \tt 1M &--&\tt 10M   & \packageBing\\
\tt 1K &--& \tt 10K    & \packageBind  & \tt 10M &--& \tt 100M & \packageBinh\\\bottomrule
\end{tabular}\caption{Call frequency}\label{tab:freq}
\end{minipage}
&
\begin{minipage}{7cm}\small
\begin{tabular}{@{}r|r@{~}r@{}r@{~}r@{}}\toprule
  &\eval & \k{evalq} & \k{eval} & \k{local}\\[-1.3mm]
           & & & \k{.parent} &\\[1.3mm]\midrule
\small Static sites &\packageStaticeval&\packageStaticevalq&\packageStaticevalparent&\packageStaticlocal \\
\small Exercised sites&\packageTriggeredeval&\packageTriggeredevalq&\packageTriggeredevalparent&\packageTriggeredlocal\\
\small Invocations&\packageEvalsRnd&\packageEvalqsRnd&\packageEparentsRnd&\packageLocalsRnd\\\bottomrule
\end{tabular}\caption{Variants}\label{tab:variantseval}
\end{minipage}\end{tabular}
\end{table}

\begin{figure}[h]
	\includegraphics[width=.7\textwidth]{traced-eval-callsites.pdf} \centering
	\caption{\eval call sites coverage of the \PkgPackages packages.}%
	\label{fig:traced-eval-callsites}
\end{figure}



Table~\ref{tab:variantseval} summarizes the use of variants, the first row has sites
(\emph{static}), the second has sites encountered during analysis
(\emph{exercised}) and the last gives calls (\emph{invocations}). Most sites and
calls go to \eval itself, \k{eval.parent} is rare, and both \k{evalq} and
\k{local} are barely used at all.

\begin{wraptable}{r}{5cm}  \small  \centering
  \begin{tabular}{r@{\,}r@{\,}l@{\,}r|r@{\,}r@{\,}l@{}r} \toprule
    \multicolumn{3}{c}{\bf \#calls} & \bf \#sites &
     \multicolumn{3}{c}{\bf \#calls} & \bf \#sites \\\midrule
    \tt 0 &--& \tt 50    & \packageRunbina & \tt 501 &--& \tt 1000   & \packageRunbine\\
    \tt 51 &--& \tt 100  & \packageRunbinb & \tt 1001 &--& \tt 1500  & \packageRunbinf\\
    \tt 101 &--& \tt 250 & \packageRunbinc & \tt 1501 &--& \tt 2000  & \packageRunbing\\
    \tt 251 &--& \tt 500 & \packageRunbind & \tt 2001 &--& \tt 3000 & \packageRunbinh\\\bottomrule
  \end{tabular}
  \caption{Normalized calls} \label{tab:cn}
  \vspace{-0.5cm}
\end{wraptable}

Table~\ref{tab:cn} shows the average count of calls from a given site and given run and
how many sites fall in that range. For instance, \packageRunbinh sites are
called over 2,000 times per run. Larger call counts suggest the presence of
loops or recursive functions, but given the data, this seems to be the exception;
\packageRunbina sites are called fewer than 50 times, most sites are invoked
once and half as many are invoked twice.

\Eval accepts any value as an argument, but if the value is not an expression,
\eval returns it unchanged. Expressions account for \packageCodepercent of
arguments. More specifically, \packageSymbolpercent are symbols (variables such
as \k{x}), \packageLanguagepercent are language objects (expressions
representing function calls), and \packageExpressionpercent are expression
objects (lists of expressions). Further inspection reveals that \k{\_inherit}
accounts for \packageGgplotsymbolpercent of symbols and comes from one site in
\k{ggplot2}.\footnote{This field is used to model inheritance in \k{ggproto}, an
  object-oriented system used by \k{ggplot2}.}


\begin{wrapfigure}{r}{6.2cm}
\hspace{-3.3cm} \includegraphics[width=0.9\textwidth]{package_size_loaded_distribution}
\caption{Loaded code} \label{fig:sizedistribution}
\end{wrapfigure}

To estimate how much executable code is injected through \eval, we measure the
size of the arguments in terms of the number of nodes. For example,
\k{expression(x+1)} has a size of 3. The large number of symbols skew the median
to \packageMedianszeval but the average size is \packageAvgszeval nodes. The
largest \eval input we observed was an expression of \packageMaxszeval nodes, a
significant chunk of code. Fig.~\ref{fig:sizedistribution} shows the
distribution of sizes for arguments of fewer than 25 nodes. Sizes drop rapidly,
there are few observations larger than 15 nodes. The long tail is omitted for
legibility. As an alternative to counting nodes, we tried measuring string
lengths of expressions after calling a function to convert values back to
strings, but these measurements were dominated by massive data objects which
could range in the MBs.

To assess how much computational work is performed in \evals, we count the
instructions executed by the interpreter. Most calls do relatively little, with
\packageSmalleventspct of calls executing fewer than 50 instructions. The violin
plot of Fig.~\ref{ev}(a) shows the distribution of short running \evals; the
data is dominated by \evals that simply perform symbol lookup. Fig.~\ref{ev}(b)
shows the distribution of work-intensive \evals which go all the way to
\packageMaxeventsRnd instructions.

\begin{figure}[h!]
\begin{tabular}{@{}c@{}c@{}}
\begin{minipage}{7.5cm}
 \includegraphics[width=\textwidth]{package_events_per_pack_small}
\end{minipage}&\begin{minipage}{7.5cm}
  \includegraphics[width=\textwidth]{package_events_per_pack_large}
\end{minipage}\\[-3mm]
\small (a) Small & \small (b) Large
\end{tabular}
 \caption{Instructions per call} \label{ev}
\end{figure}

\paragraph{Discussion.}
\Eval is widely used in CRAN packages. Nearly every fourth package contains at
least one \eval call site. However, most packages use \eval modestly. Packages
that rely heavily on \eval are mostly ones that provide statistical modeling and
simulation functions. At runtime, over a third of our scripts triggered calls to
\eval. Note that all scripts call \eval originating from the base package but
these are disregarded here. Half of the calls come from a single site, for the
rest, most packages have low call frequency. The data is consistent with the usage
of \eval for configuration and meta-programming, not in performance-sensitive
contexts such as loops. While most arguments to \eval are small, often just a
variable name, and do little work, we have also observed large arguments
and arguments that perform massive amounts of work.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{A Taxonomy of \Eval}

The previous section gave a quantitative view of \eval usage; we now try to
elucidate \emph{what} it does.

\subsection{The Expression in \Eval} \label{sec:minimized}

\begin{table}[!b]\small
\hspace*{-0.2cm}
\begin{tabular}{crrrrrc}\toprule
  \bf $min(e)$& \bf \#sites & \bf \%sites & \bf \#packages & \bf \#ops & \bf \%envir & \bf example\\\midrule
\k{X}&\packageMinimizedcallsitesa &\packageMinimizedpropsitesa &\packageMinimizedpackagea &\packageMinimizedmedianoperationsaRnd &\packageMinimizedpercentparentframesa & \k{y+1}\\
\k{F(F(X))} & \packageMinimizedcallsitesb  & \packageMinimizedpropsitesb & \packageMinimizedpackageb  & \packageMinimizedmedianoperationsbRnd & \packageMinimizedpercentparentframesb & \k{gbov( mean(x), a-1)}\\
\k{V}&\packageMinimizedcallsitesc &\packageMinimizedpropsitesc &\packageMinimizedpackagec &\packageMinimizedmedianoperationscRnd &\packageMinimizedpercentparentframesc& \k{c(42,21,0)}\\
\k{F(X)}& \packageMinimizedcallsitesd & \packageMinimizedpropsitesd & \packageMinimizedpackaged & \packageMinimizedmedianoperationsdRnd & \packageMinimizedpercentparentframesd & \k{seq\_len(iters)} \\
\k{\$} & \packageMinimizedcallsitese & \packageMinimizedpropsitese & \packageMinimizedpackagee & \packageMinimizedmedianoperationseRnd & \packageMinimizedpercentparentframese & \k{DF\$B}\\
\k{model.frame}& \packageMinimizedcallsitesf & \packageMinimizedpropsitesf & \packageMinimizedpackagef & \packageMinimizedmedianoperationsfRnd & \packageMinimizedpercentparentframesf &  \k{model.frame(formula = Z ~ U)}   \\
\k{F()}& \packageMinimizedcallsitesg & \packageMinimizedpropsitesg & \packageMinimizedpackageg & \packageMinimizedmedianoperationsgRnd & \packageMinimizedpercentparentframesg & \k{rgamma(3, 2, n = 10L)} \\
\k{FUN} & \packageMinimizedcallsitesh & \packageMinimizedpropsitesh & \packageMinimizedpackageh & \packageMinimizedmedianoperationshRnd & \packageMinimizedpercentparentframesh & \k{function(x, y) x + 3 * y} \\
\k{<-} & \packageMinimizedcallsitesi  & \packageMinimizedpropsitesi & \packageMinimizedpackagei & \packageMinimizedmedianoperationsiRnd & \packageMinimizedpercentparentframesi & \k{x[1, 2:3, 2:3] <- value}\\
\k{BLOCK} & \packageMinimizedcallsitesj & \packageMinimizedpropsitesj & \packageMinimizedpackagej & \packageMinimizedmedianoperationsjRnd & \packageMinimizedpercentparentframesj & \k{\{write.csv(iris,tf);file.size(tf)\}} \\\bottomrule
\end{tabular}
\caption{Minimized expressions} \label{tab:minimizedexpressions}
\end{table}


The expressions passed to \eval vary widely. We categorize expressions using a
minimization function which abstracts some of the incidental details of
expressions and returns a ``shape'' that can be used to group similar \evals.
The function $min(e)$, for a given expression $e$, returns a normal form. Normal
forms use \k{V} to stand in for values occurring in expression, \k{X} stands in
for variables, and \k{F} stands for functions. The function performs constant
folding of arithmetic and string expressions over base operators; for instance,
$min(\c{1+1})$ simplifies to $\c{V}$, on the ground that addition of values
likely returns a value. Value simplification takes $min(\c{c(1,2,3+2)})$ to
$\c{V}$, as a complex vector containing values is a value. Variable absorption
has $min(\c{x+y})$ become $\c{X}$; this is motivated by the fact that addition is
not an ``interesting'' operation and that \k{X} stands in for any number of
variable lookups. Function absorption simplifies nested functions to keep an
abstraction of the nesting $min(\c{g(f(x),h(z))})=\c{F(F(X))}$. There are other
simplifications; the full list can be found in our artifact. It is worth
mentioning that these simplifications are heuristics; in R, \k{1+1} is not
necessary \k{2}. The addition operator can be redefined, but it typically isn't,
or at least not in a way that would invalidate arithmetic.

Table~\ref{tab:minimizedexpressions} gives the ten most frequent shapes with the
number and ratio of sites that received arguments of that shape. Operations (ops) is
the median count of instructions performed by the interpreter when evaluating
an argument of the given shape. Envir is the ratio of sites that evaluate in a
function environment. The last column has a sample expression that normalizes to
the corresponding shape. We detail these shapes and discuss their implication for
the behavior of \eval.

\newcommand{\EE}[1]{{{\emph{\framebox{#1}}}}\\[1mm]}

\begin{tabular}{@{}p{.97\linewidth}}
  \medskip\EE{$min(e)=\c{V}$}\\[-2mm]\small Values occur in 16\% of sites, 74\% of
  those are constants such as integers, the remainder evaluate to a value (\packageNbCallSitesUniqueActualValue of sites only ever see a value). \Eval
  is needed when the expression denoting the values is constructed
  programmatically. Cases when a value is directly given to \eval, and \eval
  returns it unchanged, often occur when a computation has a default path and
  another, more interesting, path that requires evaluation.
  This shape usually runs in few interpreter steps.
  The environment in which these expressions evaluate is mostly irrelevant.
\end{tabular}

\begin{tabular}{@{}p{.97\linewidth}}
  \medskip\EE{$min(e)=\c{X}$}\\[-2mm]\small Variable lookups are the most common shape,
  \packageNbSymbolVarSitePercent are simple variable names, e.g. \k{x}. The shapes
  subsume \k{V} and built-in arithmetic operations, so a mixture of arithmetics
  and variables normalize to \k{X}. A lookup is one step of execution; if a promise
  is returned, an arbitrary number of additional steps may be needed. The median number of steps is
  \packageMinimizedmedianoperationsaRnd, suggesting that most variable reads do
  little work. Variables are often evaluated in environments that have been
  constructed programmatically; \packageMinimizedpercentparentframesa of
  expressions are evaluated in a function environment.
\end{tabular}

\begin{tabular}{@{}p{.97\linewidth}}
  \medskip\EE{$min(e)=\c{\$}$}\\[-2mm]\small This shape extends \k{X} to include lookup
  with the dollar operator, \eg~\k{x\$f}, and vector indexing, \eg~\k{x[42]} and
  \k{x[[24]]}. This takes a few more steps of evaluation on average and is
  typically used in a function environment.
  \\
  \medskip\EE{$min(e)=$~\k{<-}}\\[-2mm]\small This includes both direct assignment {\tt
  <-} and parent environment assignment {\tt <\,\!<-} as well as the \k{assign}
  function. It subsumes \k{\$}. Assignments represent the most obvious source
  of side effects in \eval. Most cases originate from trivial code generation
  where the assign expression is assembled using parse or substitute, often in
  a loop.
  \\
  \medskip\EE{$min(e)=\c{F()}$}\\[-2mm]\small This shape represents function calls without variable lookups or
  assignment. A variable is allowed in the function position; looking up
  functions does not trigger computation unless the function's name
  is bound to a promise. This shape typically does not perform much work.
\end{tabular}

\begin{tabular}{@{}p{.97\linewidth}}
  \medskip\framebox{$min(e)=\c{F(X)}$}~\EE{$min(e)=\c{F(F(X))}$}\\[-2mm]\small This shape corresponds to function
  calls whose arguments may include variable references and nested calls. Together
  they represent the most frequent shape and perform over 16 steps. They are
  frequently evaluated in function environments.
  \\
  \medskip\EE{$min(e)=\c{FUN}$}\\[-2mm]\small This shape represents function definitions without any
  computation, \eg~\k{function(x) x+1}. In addition to \k{FUN},
  \packageGeneralizedFunctionDefinitionSitesPercent sites have function
  definitions nested in other expressions.
\end{tabular}

\begin{tabular}{@{}p{.97\linewidth}}
  \medskip\EE{$min(e)=\c{BLOCK}$}\\[-2mm]\small These are multi-statement code blocks; as
  they can be large, we do not try to normalize their contents. They execute in a
  median \packageMinimizedmedianoperationsjRnd steps, usually in function
  environments.
  Essentially, the block denotes a fragment of a program to be evaluated in a
  particular way and a particular environment. The latter is what makes it
  different from a zero-argument closure. There are several use cases: unit testing
  frameworks (\eg \k{testthat}, \k{testit}), code benchmarking (\eg
  \k{rbenchmark}, \k{microbenchmark}), running code in parallel (\eg \k{foreach},
  \k{doParallel}), or deferring code execution (\eg \k{withr}).
\end{tabular}

\begin{tabular}{@{}p{.97\linewidth}}
  \medskip\EE{$min(e)=\c{model.frame}$}\\[-2mm]\small The \k{model.frame} function
  returns a data frame resulting from fitting the model described in a formula.
  This shape subsumes \k{F(F(X))}, \k{FUN}, and assignments. It is the single most
  popular function invoked from \eval. Each call does a median of 2K instructions.
\end{tabular}

\paragraph{Discussion.} The number of different shapes that any given
\eval site sees is an indication of the versatility of that site.
\packageNbOneMinimizedPercent of sites only see a single expression shape. It
would be encouraging if one could, given a small training set, predict the shape
of \evals to come. In our corpus, only a few sites are highly polymorphic with
more than eight shapes. An example of those is the pipe operator of the
\k{magrittr} package which is used to compose functions, \eg instead of
\k{f(g(h(x),y),z)} one can write \k{h(x) \%>\% g(y) \%>\% f(z)}. As there are many
different patterns of use, there are also many different shapes. In comparison
with R, JavaScript's \eval usage was more straightforward and more predictable,
as reported by \citet{oopsla12b}, with 98\% of sites with only one shape. On the
other hand, there are \packageNbSimpleMinimizedOne sites that only receive one
of the simple shapes (\ie\xspace \k{X}, \k{V}, \k{\$} or \k{<-}), and
\packageNbSimpleMinimizedMore sites get multiple simple shapes. Among these
sites, there are many cases where \eval could be possibly replaced by simpler constructs
such as \k{get} to lookup a name in an environment, \k{assign} to set a value to
a name in an environment, or \k{do.call} to call a function reflectively.

\subsection{The Environments of \Eval}\label{sec:env}

Contrary to JavaScript, in R, the environment of \eval can be specified by its
\k{env} argument. This gives users control over what is visible to the
computation started by \eval and the potential reach of its side-effects. We
distinguish the following kinds of environments:

\begin{itemize}[---]
\item \emph{Function:} environments for the local variables of some function
  currently active on the call stack. Obtained by calling \k{parent.frame()} or
  \k{sys.frame()}.
\item \emph{Synthetic:} environments built from data structures such as lists,
  data.frames, or constructed explicitly with \k{new.env}, \k{list2env}, or
  \k{as.environment} or the empty environment.
\item \emph{Global:} environments in which scripts or interactive commands are
  evaluated.
\item \emph{Package:} environments of libraries.
\end{itemize}


Table~\ref{tab:highlevelenvironments} shows that most calls evaluate in the
scope of a function; global is a distant second. This means that most reads and
writes act on local variables. But of which function? Table~\ref{tab:funoffset}
gives the offset of that function on the call stack: 0 is the function that called
\eval, 1 is that function's caller, and so on. In 81\% of cases, \eval uses
its caller's environment -- the variables of the function where the call to \eval
textually occurs are read and written. About 1.5\% of sites evaluate their
argument three frames up the call stack or above. Modular reasoning is thus
impossible in R. Since the actions of \eval happen at a distance, understanding
any given code snippet requires knowing which functions may be called
transitively from that snippet. In \packageNbOneCategoryEnvirSitePercent of
the sites, only one kind of environment is observed.

\begin{table}[h]
  \centering\small\hspace{-.5cm}
\begin{minipage}{3.7cm}
  \begin{tabular}{@{}rrr@{}}\toprule
 \bf Kind & \bf \#sites & \bf \%sites \\\midrule
 Function & \packageNbFunctionEnvSites &  \packageNbFunctionEnvSitePercent\\
 Synthetic & \packageNbSyntheticEnvSites & \packageNbSyntheticEnvSitePercent \\
 Global &  \packageNbStrictGlobalEnvSites & \packageNbStrictGlobalEnvSitePercent \\
 Package & \packageNbPackageNamespaceEnvSites & \packageNbPackageNamespaceEnvSitePercent \\\bottomrule
\end{tabular}
\caption{Kinds per site} \label{tab:highlevelenvironments}
\end{minipage}\hspace{-.2cm}
\begin{minipage}{3.7cm}\centering
  \begin{tabular}{@{}rrr@{}}\toprule
 \bf Offset & \bf \#sites & \bf \%sites \\\midrule
  \packageCallerEnvHierarchyNamea & \packageCallerEnvHierarchySitesaRnd & \packageCallerEnvHierarchySitePercenta \\
  \packageCallerEnvHierarchyNameb& \packageCallerEnvHierarchySitesbRnd & \packageCallerEnvHierarchySitePercentb \\
  \packageCallerEnvHierarchyNamec& \packageCallerEnvHierarchySitescRnd & \packageCallerEnvHierarchySitePercentc  \\
$\ge 3$& \packageNbFarAwayCallerSites &  \packageNbFarAwayCallerSitePercent \\\bottomrule
 \end{tabular}
\caption{Function offset}\label{tab:funoffset}
\end{minipage}\hspace{-.2cm}
\begin{minipage}{3.7cm}
  \begin{tabular}{@{}rrr@{}} \toprule
\bf Parent & \bf \#sites & \bf \%sites \\\midrule
Function & \packageNewEnvCategorySitesa & \packageNewEnvCategorySitePercenta \\
Package & \packageNewEnvCategorySitesb &  \packageNewEnvCategorySitePercentb\\
Global & \packageNewEnvCategorySitesc & \packageNewEnvCategorySitePercentc \\
    Empty & \packageNewEnvCategorySitesd & \packageNewEnvCategorySitePercentd \\\bottomrule
\end{tabular}
\caption{Wrapper envs.} \label{tab:newenvs}
\end{minipage}\hspace{-.2cm}
\begin{minipage}{3.7cm}\centering
  \begin{tabular}{@{}ccc@{}} \toprule
 \bf \#kinds & \bf \#sites &  \bf \%sites \\\midrule
 \packageNbCategoryEnvira & \packageNbCategoryEnvirSitesaRnd &  \packageNbCategoryEnvirPercenta\\
 \packageNbCategoryEnvirb &  \packageNbCategoryEnvirSitesbRnd & \packageNbCategoryEnvirPercentb \\
 \packageNbCategoryEnvirc & \packageNbCategoryEnvirSitescRnd &  \packageNbCategoryEnvirPercentc\\
 \packageNbCategoryEnvird & \packageNbCategoryEnvirSitesdRnd & \packageNbCategoryEnvirPercentd\\\bottomrule
\end{tabular}\caption{Multiplicities}\label{tab:polyenvir}
\end{minipage}\hspace{-1cm}
\end{table}

Each synthetic environment has a parent that is specified when calling
\k{new.env}. When \k{envir} is a list or a data frame, \eval uses its third
argument (\k{enclos}). The parent is used to search for variables not found in
its child (side-effects stay in the child). Table~\ref{tab:newenvs} shows parent
kinds for synthetic environments. Most of them are functions.

Global \evals split between intentional and accidental one. Direct references to
the top-level, using \k{globalenv()} or \k{.GlobalEnv}, are rare; they occur in
only \packageNbExplicitGlobalSites sites. Thus we suspect most uses of global
are accidental. They arise from the fact that our corpus consists of many code
snippets that are run at the top-level; global is thus the caller of \eval. This is
noteworthy because writes to global variables are visible to all functions and
are not reclaimed by the garbage collector. So accidental uses may pollute that
namespace. Table~\ref{tab:polyenvir} gives the number of kinds seen at a given
call site.

\paragraph{Discussion.}
The data presented here is not surprising. The main use of \eval is to provide a
customizable extension mechanism for the behavior of functions. They are a way
to parameterize the function with any behavior that can be expressed in R. The
behavior of \eval within its enclosing function is to read and write variables,
mostly read, and very rarely, delete variables. There are also some cases where
new variables are injected in a function. Usually, this is in the direct caller,
but it can sometimes take effect several frames up the call stack. There is
something brittle about code relying on the position of a caller: a lot of
refactoring may break code that does that.

One bit of information that we lack is how the environment was obtained. Our
expectation is that the expression was extracted from a promise using
\k{substitute}, perhaps modified, and then evaluated with the environment coming
from the same promise. We believe the case where \eval is provided with the results
of programmatically selecting some call stack to be less frequent.

Synthetic environments are relatively frequent. Common uses-cases include
the evaluation of an expression in a sandbox or using a data structure as
environment. For example, one could evaluate a method of an object and use an
environment to hold the object's fields.

We have already explained the popularity of global environments. As for package
environments, they are used in only \packageNbPackageNamespaceEnvSites sites.
This is probably for the best as mutating the bindings of a loaded package is
frowned upon, and R tries to discourage it.

\subsection{The Origins of \Eval}

Where does the expression passed to \eval come from? There are various means of
creating an expression; often these means correlate with a particular use case.
Our analysis records the values returned by some functions of interest as well
as their arguments. We build a direct acyclic graph that tracks the origin
of the values that are given to \eval. Fig~\ref{fig:provgraph} shows an example
of the origin graph for the expression \k{e}.
The origin of \k{e} includes both \k{parse} and \k{quote}, the starting nodes. We pick one origin by traversing the graph from the terminal leaf, \ie from the \eval node, following the left-hand side
member of assignments until reaching a starting node. It represents the origin that is
further modified to yield the expression passed to \eval. In this example, that
origin is \k{parse}.

\begin{figure}[H]
  \begin{minipage}{.39\textwidth}
    \vspace{-5mm}
\begin{lstlisting}
 > e <- parse(text = "a;b")
 > e[[2]] <- quote(c) # e is a;c
 > eval(e)
\end{lstlisting}
  \end{minipage} \hspace{2cm}
 \begin{minipage}{.4\textwidth}
	\centering\scalebox{.7}{
	\begin{tikzpicture}[
		every node/.style={draw, rounded corners, fill=LightGray, text width = 2cm, align = center, thick}
		]
		\node (E) at (2,0) {\k{eval(e)}};
		\node[text width = 3cm] (CA) at (2, 1.5) {\k{e[[2]] <-quote(c)}};
		\node (Q) at (4, 3) {\k{quote(c)}};
		\node[text width = 4cm] (A) at (0, 3) {\k{e <- parse(text = "a;b")}};
		\node[text width = 3cm] (P) at (0, 4.5) {\k{parse(text = "a;b")}};

		\draw[<-, >=latex] (E) -- (CA);
		\draw[<-, >=latex] (CA) -- (Q);
		\draw[<-, >=latex] (CA) -- (A);
		\draw[<-, >=latex] (A) -- (P);
	\end{tikzpicture}}
\end{minipage}
\caption{Example of an origin graph} \label{fig:provgraph}
\end{figure}


\begin{table}[!b]\small\centering
\begin{tabular}{c@{\hspace{2cm}}c}
  \begin{tabular}{lcc}\toprule
\bf Provenance & \bf \#sites & \bf \%sites \\\midrule
		\packageProvenanceNamea & \packageNbProvenanceSitesa & \packagePercentProvenanceSitesa \\
		\packageProvenanceNameb & \packageNbProvenanceSitesb & \packagePercentProvenanceSitesb \\
		\packageProvenanceNamec & \packageNbProvenanceSitesc & \packagePercentProvenanceSitesc \\
		\packageProvenanceNamee & \packageNbProvenanceSitese & \packagePercentProvenanceSitese \\
		\packageProvenanceNamef & \packageNbProvenanceSitesf & \packagePercentProvenanceSitesf \\
		\packageProvenanceNameg & \packageNbProvenanceSitesg & \packagePercentProvenanceSitesg \\
		\packageProvenanceNameh & \packageNbProvenanceSitesh & \packagePercentProvenanceSitesh \\
		\packageProvenanceNamei & \packageNbProvenanceSitesi & \packagePercentProvenanceSitesi \\
		\packageProvenanceNamel & \packageNbProvenanceSitesl & \packagePercentProvenanceSitesl \\
		\packageProvenanceNamen & \packageNbProvenanceSitesn & \packagePercentProvenanceSitesn \\\bottomrule
\end{tabular}
&
\begin{tabular}{rrr} \toprule
\bf Origin  & \bf \#sites & \bf \%sites \\\midrule
Reflection &  \packageNbReflectionSites & \packageReflectionSitesPercent\\
String & \packageNbStringSites & \packageStringSitesPercent \\
Constructed & \packageNbConstructedSites & \packageConstructedSitesPercent \\
Environment & \packageNbSymbolSites & \packageSymbolSitesPercent \\
External & \packageNbExternalSites & \packageExternalSitesPercent \\\bottomrule
\end{tabular}
\end{tabular}
\medskip
\caption{Origins}\label{tab:provenance}
\end{table}

To have a high-level view of provenance, we classify functions into the
following five categories:

\begin{itemize}[---]
\item {\it Reflection:} use of \k{match.call} to reflectively capture the
  expression that invoked this function. Function arguments are promises, and
  \k{substitute} is used to retrieve their source.
\item {\it String:} created from strings by invoking \k{parse},
  \k{str2lang}, or \k{str2expression}.
\item {\it Constructed:} invoked \k{quote} or \k{expression}, or by building with
  \k{call} or \k{as.call}.
\item {\it Environment: } created with \k{as.name} or \k{as.symbol}, typically
  to read a non-local environment.
\item {\it External: }  call to a C function.
\end{itemize}

Table~\ref{tab:provenance} summarizes origins. It shows frequencies by function
and by category. For technical reasons, we misclassify a small number of sites.
Manual inspection of numerous examples suggests that errors are rare. Some sites
are counted multiple times as they are invoked with different origins. Strings
correlate with dynamic code loading as done by \k{source} and \k{sys.source}.
Few calls (\packageNbParseFromFileSites in total) consume the result of calling
\k{parse} on a file. Most build strings programmatically.


\paragraph{Discussion}
The main use cases for \eval involve using \k{match.call}, or \k{substitute} to
access and transform arguments of a function. Constructing expressions from
strings is also a common use case. The constructed category shows that most
\evals come from existing code that was modified by the programmer before
invoking \eval. Both constructed and reflection categories roughly correspond to
meta-programming. Some uses could be replaced by macros if the R designers could
be convinced to overcome their distaste for those.

\subsection{The Effects of \Eval}

\Eval may perform side-effects. We care about effects that are visible after a
call finishes, \ie variable definitions, updates, and removals. Knowing the
environments in which these side-effects happen can help determine the impact of
\eval on our ability to reason about the code. Our analysis records information
about every environment. From the recorded data, we discard side-effects coming
from unit testing frameworks as they use \eval to run all their tests and thus
dominate the side-effect data.\footnote{The corpus has \k{RUnit, testthat,
    tinytest} and \k{unitizer} testing frameworks.}

We record \SEAllRnd side-effects from \SEAllCallsRnd calls and \SEAllSites
sites. The challenge is to remove accidental side-effects caused by the R
virtual machine implementation and not user code. For example, the
\k{.Random.seed} variable is saved and restored from and to the global
environment every time a statistical routine is called. Filtering out accidental
side-effects leaves us with \SEUserRnd writes from \SEUserCallsRnd calls (in
\SEUserSites sites and \SEUserFunctions functions). In this set, \SEFunsNighty functions are
responsible for 90\% of side effects. Half of those come from just three
functions: \k{plyr::allocate\_column} (allocates space for a new data frame
column), \k{withr::execute\_handlers} (executes deferred expressions), and
\k{foreach::doSEQ} (executes an expression on each element in a collection,
possibly in parallel). Most of the sites (\SESitesInEnvirRatio) update
the environment specified by the \k{env} parameter.

\begin{table}[!h]
  \begin{tabular}{lrrrr}
    \toprule
    \bf Environments & \bf \#sites & \bf \%sites & \bf \#funs. & \bf \%funs. \\%
    \midrule
    \expandableinput tag/table-se-target-envs.tex
    \bottomrule
  \end{tabular}
  \caption{Target environments for side-effects} \label{tab:se-env}
\end{table}

Table~\ref{tab:se-env} shows environment kinds where side-effects happen.
Function environments distinguish between \emph{local}, the caller environment
(offset 0), and \emph{function} (offset >0). \emph{Synthetic} represents
constructed environments. \emph{Object} is used to denote the environments
attached to objects and classes in the S4 and R6 object systems. \emph{Multiple}
denotes cases where side-effects to more than one kind originate from one site.
The table gives the number of call sites of \eval (and the ratio) performing
side-effects in a particular environment kind. The table also gives the number of
functions in which these sites occur (and ratio).

Most sites, \SESitesInOneClass, do all their side-effects consistently in one
kind of environment. The same happens at the function level. Almost half of the
sites (over a third of the functions) do side effects in either \emph{Local} or
\emph{Object} environments.

Table~\ref{tab:se-types} shows recorded effects. There are over 5M updates. In
terms of calls, we primarily see assignments, followed by definitions. This is
expected. A subsequent \eval call will turn a definition into an update. The
most dangerous side effect is variable removal, as it means that after a call to
\eval some binding in some environments will disappear. While rare, this
happens, but the vast majority comes from a single site
(\k{withr::execute\_handlers}). This makes sense as it is used to defer
evaluation of an expression to after the function exit and thus used for clean
up. It is used almost exclusively by the \k{tidyselect} package for removing the
reference to the current quosure environment while interpreting a data frame
column selectors.\footnote{\cf \url{https://tidyselect.r-lib.org/}}

Looking closely at the value types in variable updates, we observe that the
majority of \eval sites involve basic R vectors (\SEBasicTypeRatio) and lists
(\SEListTypeRatio). From the perspective of a compiler, we would like to know
how many sites change function bindings. In our corpus, this happens in only
\SEClosureType sites; \SEClosureTypeLocal of them do that in the local
environment. We manually inspected a few of these sites; except for manual
injection of parameters into a \k{model.frame} execution environment, we did not
find a common use case.

\begin{table}[h]
  \small
  \centering
  \begin{tabular}{lrrrrrr}
    \toprule
    \bf Side effect & \bf \#events & \bf \%events & \bf \#calls & \bf \%calls & \bf \#sites & \bf \%sites \\%
    \midrule
    \expandableinput tag/table-se-types.tex
    \bottomrule
  \end{tabular}
  \caption{Types of \eval side-effects} \label{tab:se-types}
\end{table}

Out of the minimized expressions, it is \k{BLOCK}, \k{<-} and \k{F(F(X))} that
contributes to the vast majority of side effects. Concretely, 92\% of \k{BLOCK},
87\% of \k{<-}, and 15\% of \k{F(F(X))} expressions do side effects. In the case
of \k{BLOCK}, most of them happen in the environment passed to the \eval call
(default is the parent environment). For \k{<-} it is 15\%. This form is
dominated by the \k{plyr::allocate\_column} function that side-effects in the
environment containing the data frame to which it allocates a new column.
Without this call, \k{<-} is similarly predictable with 96\% of side effects
happening in the passed environment. For \k{F(F(X))}, it is less clear as 58\%
of side effects happen in a different environment to the one that was passed to
\eval.

\paragraph{Discussion} In JavaScript, assignments in \eval can happen in either
local scope or less often, when called through an alias, in the global scope.
In R, given the support for first-class environments, it can happen anywhere,
making \eval more dangerous than it already is. However, the data suggest
that first, side-effects from \eval are not as widespread as in the case of
JavaScript,\footnote{\citep{ecoop11} shows that in the \emph{Interactive}
  scenario, \eval in Javascript performs, store events can reach up to 40\% of
the events, and 7\% to 8\% of the \eval do side effects in the global scope. }
and that over half of them happen in a predictable environment. This gives a
ray of hope for a hypothetical R compiler. Even though \eval can do anything
anywhere, the data suggests most effects are sane.

\section{Usage of \eval}

The R language was intended to be extensible. The combination of lazy
evaluation, \k{substitute}, and \k{eval} are some of the tools given to
developers to this end. To understand \emph{why} developers use \eval, we
manually inspected the top 117 sites, which contribute to 90\% of the calls in
the corpus. We present examples from nine classes from this batch. The
classification is not exhaustive as we only study a fraction from the
\PkgEvalCallSites call sites in our corpus, and many uses of \eval do not fit
in a specific category. Instead, the goal is to demonstrate the wide variety of
uses to which \eval is put to use. At the high level, the usage can be grouped
into two groups: one contains patterns that aim to provide better
API for R users and the other focuses on simplifying implementation.

\subsection{Better API}

This category contains \eval used to develop a better API in terms of
ergonomics, extensibility, and ease of use. This is important given
that R is often being used interactively for data exploration.

\paragraph{Non-standard Scoping} \Eval allows functions to resolve symbols in
different environments than the current one. For example, the \k{data.table}
package redefines the subsetting operator, \k{[}\footnote{Defined as a triplet
  \texttt{[i, j, k]}, where expression \texttt{j} is used to calculate a subset
of rows from \texttt{i} grouped by \texttt{k}.}, to enable compact queries on
data frames. The example below shows the use of this operator on the
\k{flights} data frame to compute the average departure delays of Delta flights
in 2014 by the origin airport. The symbols \k{carrier}, \k{year},
\k{dep_delay}, and \k{origin} are not looked up in the current environment but
in the \k{flights} data frame.

\begin{lstlisting}[caption={\k{data.table::[}}, captionpos=b]
> flights[carrier=="DL" & year == 2014, mean(dep_delay), by=origin]
#    origin       V1
# 1:    LGA 11.35083
# 2:    EWR 14.96171
# 3:    JFK 12.45414
\end{lstlisting}\medskip

At its core, the \k{[} operator uses \k{substitute} to capture its operand
expressions, transforms them, and evaluates them using \eval in the given data
frame. We omit the implementation as it spans over 1700 lines at the time of
this writing\footnote{Its implementation can be found at:
  \url{https://github.com/Rdatatable/data.table/blob/master/R/data.table.R}}.

Non-standard scoping is an important use case of \eval in R. It enables the
design of functions that require less typing and syntactic noise at the cost of
some ambiguity. Since R is used primarily interactively, this trade-off is
justifiable.

\paragraph{Domain-Specific Language} A domain-specific language leverages R's
grammar but redefines its semantics in a suitable way. The example below
illustrates string interpolation. The \k{glue} function from the \k{glue}
package extracts snippets of code enclosed between braces, evaluates them using
\eval, and splices their results to construct the result.

\begin{lstlisting}[caption={\k{glue::glue}}, captionpos=b]
> greeting <- "Hello"
> glue('{greeting} World!')
# Hello World!
\end{lstlisting}\medskip

The \k{glue} package contains a variant of \k{glue} function that leverages
non-standard scoping for interpolation in a custom environment. For example,
the following snippet pipes the subsetted data frame into the \k{glue_data}
function used to resolve the symbols for string interpolation.

\begin{lstlisting}[caption={\k{glue::glue_data}}, captionpos=b]
> flights[carrier=="DL" & year == 2014, mean(dep_delay), by=origin] |>
    glue_data("{origin} has average delay of {round(V1)} min")
# LGA has average delay of 11 min
# EWR has average delay of 15 min
# JFK has average delay of 12 min
\end{lstlisting}

\paragraph{Behavioral Extension} Sometimes it is convenient to allow users to
extend the behavior of a library function. \Eval allows clients to provide a
simple text string that is executed in the context of the function. The example
here allows users to provide formulas as strings, such as \k{"exp(-x^2/2)"},
the contract being that the text can refer to some variable \k{x} the called
function will set up.\footnote{The function is used to generate a sequence of
  random numbers using the adaptive rejection sampling algorithm and the string
formula is used to describe the target density.}

% To remove "Listing i" in the captions from this point, as we do not refer to them by number
% We define and refer to listings in 2.2 so we need to put that captionsetup only here
\captionsetup[lstlisting]{labelformat=empty} 
\begin{lstlisting}[caption={\k{AdapSamp::rARS}}, captionpos=b]
 function(n,formula) {
   p <- function(x) eval(parse(text=formula))
   ...
 }
\end{lstlisting}

\paragraph{Extracting Varargs} \Eval is used to obtain the source code of the
arguments passed to a vararg parameter (\k{...}). Concretely,
\k{substitute(alist(...))} yields an expression representing a call to
\k{alist} with the \k{...} expanded to the arguments supplied to the function.
Passing this to \eval returns a list of the unevaluated argument
expressions. In the following example, it is used to find and return the value of the first expression that evaluates to non-null value. The extracting varargs pattern is needed to avoid premature promise forcing.

\begin{lstlisting}[caption={\k{statnet.common::NVL}}, captionpos=b]
 function(...) {
   for (e in eval(substitute(alist(...)))) {
     if (!is.null(eval(e, parent.frame()))) break
   }
   e
 }
\end{lstlisting}

\paragraph{Controlled Evaluation} \Eval can be used to control when and if
expressions are evaluated. For example, \k{assertthat} provides users with the
ability to make assertions and, if they fail, produce legible error messages.
The \k{assertthat::see_if} function accepts a vararg with a list of
expressions. It extracts these expressions using the extracting varargs
pattern and evaluates them sequentially in the caller's environment using
\k{eval}. If an expression does not hold, an error is generated.

\begin{lstlisting}[caption={\k{assertthat::see_if}}, alsoletter={\_}, captionpos=b]
 function(..., env=parent.frame(), msg=NULL) {
   asserts <- eval(substitute(alist(...)))
   for (assertion in asserts) {
     res <- tryCatch({
       eval(assertion, env)
     }, assertError=function(e) { structure(FALSE, msg=e$message) })
   ...
 }
\end{lstlisting}

\paragraph{Shadowing} Some packages use \eval to implement variations of the
\k{base} R functions. For example, the \k{igraph} package provides the
\k{do_call} function shown below. This is a variant of the builtin \k{do.call}
function with different semantics for resolving the function name. It
constructs a call from a name and a list of arguments and passes it to \eval.

\begin{lstlisting}[caption={\k{igraph::do\_call}}, captionpos=b]
 function(f,...,args=list(),env=parent.frame()) {
   f <- substitute(f)
   eval(make_call(f,...,args), env)
 }
\end{lstlisting}

\subsection{Implementation simplification}

The patterns in this category use \eval to simplify implementation in terms of
avoiding repetitive and boilerplate code.

\paragraph{Code Generation} \Eval can be used to generate code that would
either be tedious to write by hand or that is only known after deployment. The
following code snippet for the \k{Rcpp} package uses \eval to automatically
generate R bindings to C++ methods.

\begin{lstlisting}[caption={\k{Rcpp::.makeCppMethods}}, captionpos=b]
 function(methods, env) {
   for(what in cppMethods)
     methods[[what]] <-
       eval(substitute(function(...)CppObject$what(...)), env)
   ...
 }
\end{lstlisting}

\paragraph{Boilerplate Removal} A variant of code generation is to let users
write compact code that is expended via \eval and \k{match.call}. The example
uses \k{match.call} to access the expression with which the function is called.
The following three lines construct a call to \k{stats::model.frame} with
argument text of parameters \k{'formula'}, \k{'data'}, and \k{'weights'}. Then,
the call expression is evaluated in the parent environment. The use of
\k{match.call} avoids repeated use of \k{substitute} for extracting the
argument expressions. It is extensible as new parameter names can be easily
added. This example illustrates one of the most recurring uses of \eval by
packages that do statistical modeling, and relates to the \k{model.frame} shape
in Table~\ref{tab:minimizedexpressions}.

\begin{lstlisting}[caption={\k{survival::survfit.formula}}, captionpos=b]
 function(formula, data, weights, ...) {
   Call <- match.call()
   indx <- match(c('formula', 'data', 'weights'), names(Call), nomatch=0)
   temp <- Call[c(1, indx)]
   temp[[1L]] <- quote(stats::model.frame)
   mf <- eval.parent(temp)
   ...
 }
\end{lstlisting}
\medskip

Wrapping functions in R is somewhat harder than in other languages because of
default arguments, varargs, and missing arguments. The combination of
\k{match.call} and \eval can be used to forward the current call's arguments to
another function without listing all the argument names. This pattern eases the
maintenance of wrappers. For example, the \k{base::write.csv} function passes
most of its arguments unchanged to the more general \k{base::write.table}
function.

\begin{lstlisting}[caption={\k{base::write.csv}}, captionpos=b]
 function (...) {
   Call <- match.call(expand.dots = TRUE)
   Call$sep <- ","
   Call$dec <- "."
   Call$qmethod <- "double"
   Call[[1L]] <- as.name("write.table")
   eval.parent(Call)
 }
\end{lstlisting}

\paragraph{Obfuscation}  A few packages use \eval to bypass the restrictions
imposed by the \k{R CMD CHECK} tool. This tool enforces some well-formedness
rules on a submitted package before accepting it for inclusion in CRAN. Some
static checks ensure that the package code does not use certain restricted
functions. Package authors use \eval to obfuscate their code to get around this
limitation. The example below mutates the variable \k{s} in the package
environment. However, that is locked by default and unlocking it requires
\k{unlockBinding} which is a restricted function. To work around this, the call
to \k{unlockBinding} is done through \eval.

\begin{lstlisting}[caption={\k{aibd::scalaEnsure}}, captionpos=b]
 function() {
   env <- parent.env(environment())
   eval(parse(text=paste0('unlockBinding("s", env)')))
   assign("s", s, envir=env)
   lockBinding("s", env)
   ...
 }
\end{lstlisting}\medskip

\section{Discussion}

In R, \eval is used chiefly for meta-programming and accessing remote
environments. Unlike JavaScript, which according to ~\citet{ecoop11} had a small
set of well-defined patterns that could be rewritten without \eval, our results
suggest that \eval is an integral part of programming in R.

The cases where \eval appears to be an overkill include simple expression shapes
such as \k{X}, \k{V}, \k{\$}, \k{<-}, and \k{FUN}. Variable lookup in a remote
environment can be performed by the builtin \k{get} function. A similar case can
be made for assignment and the \k{assign} function. There is a dedicated
\k{do.call} function to perform function calls. However, the unnecessary uses of
\eval are not easy to find and often can only be uncovered by manual analysis.
Dynamic analysis is limited due to coverage issues, and static analysis of R
remains an open problem.


\begin{lstlisting}[caption={Unnecessary use of \eval},label=lst:unnecessary]
 PerformanceAnalytics::chart.QQPlot <- function (d="norm",dp,...) {
   q.f <- eval(parse(text=paste0("q",d)))
   z <- NULL
   eval(parse(text=paste0("z<-q.f(",dp,",...)")))
\end{lstlisting}\medskip

For the example in Listing~\ref{lst:unnecessary}, the function uses \eval to
lookup a target function name from a constructed string. Then it constructs a
call with the arguments that are passed to the current function. \Eval is
overkill in this case: a semantically equivalent function body can use \k{get}
to perform the lookup and then call the resulting function directly.

\begin{lstlisting}
 q.f <- get(paste0("q",d))
 z <- q.f(dp, ...)
\end{lstlisting}

Another example, from \k{coin::copyslots}, constructs an expression that accesses
fields of an object and copies them.

\begin{lstlisting}
  eval(str2lang(paste0("target@", s, " <- source@", s)))
\end{lstlisting}

% TODO: show how will it look with symbolic field read and write

This can be replaced by symbolic field reads and writes:

% This should be enough:
\begin{lstlisting}
 slot(target, s) <- slot(source, s)
\end{lstlisting}


We have not yet touched on alternative implementations of \eval. The tidyverse
libraries\footnote{An opinionated collection of R packages designed for data
  science. It consists of some of the most popular packages.} include their own
implementation of \eval called \k{rlang::eval\_tidy}~\cite{tidyverse}, which
departs from \eval in two ways. First, it supports the evaluation of quosures,
custom objects used for metaprogramming that bundle expressions with an
environment. The \k{eval\_tidy} function accepts a data mask argument, a set of
bindings such as a data frame or list, which takes precedence over the
environment. Effects such as assignments happen in the data mask, and
expressions such as \k{return()} do not work since the data mask does not
correspond to a frame on the call stack.

\section{Conclusion}

The \eval function is used widely, and in varied ways in R. The function is an
essential tool for language implementers. Our analysis observed that the base
libraries heavily depend on \eval, and any R program will end up calling it
through the core of the language. Independently developed libraries often use
\eval in subtle ways, mostly to perform macro-programming tasks. Our review of
code written by less experienced users suggests that \eval is exceedingly rarely
used. So, it is fair to conclude that most R programmers never have to
write a call to \eval, but the code they write would not run without it.

\Eval is thus a challenge for automated program understanding. Program analysis
and transformation tools or compilers must assume the worst when faced with code
that calls this function. We have observed all sorts of side-effects with
various degrees of visibility.

While our results are not encouraging in general, we have observed many cases
where \eval is used in disciplined and predictable ways. While in the general
case \eval is hell, there are many cases where it is just a function. It does
not appear that a general-purpose replacement for \eval is possible; in future
work, we hope to focus on special cases and propose tools that target particular
subsets of call sites with some common properties.


\begin{acks}
  This work has received funding from the
\grantsponsor{NSF}{National Science Foundation}{} awards
\grantnum{NSF}{1759736}, \grantnum{NSF}{1544542},
\grantnum{NSF}{1925644}, and \grantnum{NSF}{1910850}, the
\grantsponsor{BC}{Czech Ministry of Education, Youth and Sports from
  the Czech Operational Programme Research, Development, and
  Education}{}, under grant agreement No.
\grantnum{BC}{CZ.02.1.01/0.0/0.0/\-15\_003/0000421}, and the
\grantsponsor{ELE}{European Research Council (ERC) under the European
  Union's Horizon 2020 research and innovation programme}{}, under
grant agreement No.  \grantnum{ELE}{695412}.
\end{acks}


\bibliography{bibexport}

\end{document}
