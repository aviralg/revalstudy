---
title: "Provenance analysis"
author: "Pierre Donat-Bouillud"
output:
  html_document:
        gallery: false
        toc: true
        toc_depth: 3
        toc_float: true
        df_print: paged
date: "`r Sys.Date()`"
editor_options: 
  chunk_output_type: console
params:
  #base_dir: Data/package/
  base_dir: /mnt/ocfs_vol_00/project-evalr/evalr-experiment/run/preprocess/package/
  calls_path: summarized.fst
  corpus_path: corpus.txt
  static_path: evals-static.csv
  force_rebuild: FALSE
---

```{r setup, include=FALSE}
knitr::knit_hooks$set(time_it = local({
  now <- NULL
  function(before, options) {
    if (before) { # record the current time before each chunk
      now <<- Sys.time()
    } else { # calculate the time difference after a chunk
      res <- difftime(Sys.time(), now)
      # return a character string to show the time
      paste("Time for this code chunk to run:", res, units(res))
    }
  }
}))

knitr::opts_chunk$set(
  echo = TRUE,
  fig.align = "center",
  fig.retina = 2,
  fig.width = 10,
  cache.lazy = FALSE
)

now <- Sys.time()

library(tidyverse)
library(fst)
library(fs)
library(DT)

source("inc/latextags.R")
source("inc/functions.R")
source("inc/paths.R")
theme_set(theme_minimal())

dataset_name <- basename(params$base_dir)

# Tags will be prefixed by the dataset name
create_tags(path(TAGS_DIR, paste0(dataset_name, "_provenance2.tex")), prefix = dataset_name, default = TRUE)
# Also use ggsave_prefix instead of ggsave if you need to save a graph

calls_path <- paste0(params$base_dir, params$calls_path)
corpus_path <- paste0(params$base_dir, params$corpus_path)
static_path <- paste0(params$base_dir, params$static_path)

provenance_path <- paste0(params$base_dir, params$provenance_path)

lock_path <- paste0(params$base_dir, ".provenance2-lock.fst")
min_path <- paste0(params$base_dir, "Eprov2.fst")

nb_eval_call_sites <- function(dataset) {
  dataset %>% pull(src_ref) %>% n_distinct()
}

```

# Loading datafiles

```{r loading_fst}
tibble(package = read_lines(corpus_path)) -> C_raw
read_csv(static_path) %>% semi_join(C_raw, by = "package") -> P

rebuild <- TRUE

E_prov <- NULL

if (file.exists(lock_path)) {
  saved <- read.fst(lock_path)[[1,1]]
  if (saved == file.size(calls_path)) {
    read_fst(min_path) %>% as_tibble() -> E_prov
    rebuild <- FALSE
  }
}

if(params$force_rebuild || rebuild) {
  read_fst(calls_path) %>% as_tibble() -> E_raw
  
  E_raw <- E_raw %>% mutate(envir_expression = if_else(envir_type == "NULL" & is.na(envir_expression), "NULL", envir_expression))
  
  E_raw %>% select(
    run_package = package, #      The package which was run to trigger the eval
    ev_variant = eval_function, # Which eval variant was called
    duplicates = nb_ev_calls, #   Number of identical eval calls (weight)
    src_ref = eval_call_srcref, # Source ref for the eval call site
    file, #                       Script file name (name of this run)
    ev_package = eval_source, #   Package of the call site
    type = expr_resolved_type_tag, #   Argument type
    ev_call = eval_call_expression,
    ev_expr = expr_expression,
    ev_class = expr_resolved_class, # S3/S4 class
    caller_expression,
    provenance, # the main provenance (i.e. climbing up LHSs)
    provenance_args,
    nb_provenances,
    nb_operations,
    longest_path_size,
    all_provenances
  ) -> E_prov
  
  
  #E_prov %>% write_fst(min_path)
  sz <- file.size(calls_path) %>% as_tibble()
  #write.fst(sz, lock_path)
}

C_raw -> C
corpus_size <- nrow(C)
```

# Description of the data files

```{r packages}
nb_eval_calls <- count(E_prov, wt = duplicates)

nb_call_sites <- E_prov %>% pull(src_ref) %>% n_distinct()
```


There are `r nb_eval_calls` eval calls and `r nb_call_sites` eval call sites in the dataset.


In the dataset, the `provenance` column refers to the main provenance of an expression passed to `eval`. It is obtained by traversing the provenance graph and following the LHSs.

# Provenances using the representative provenance

## Provenance in numbers of calls

```{r prov_number_calls}
provenance_calls <- E_prov %>% count(provenance, wt = duplicates, sort = TRUE) %>% 
  mutate(pc = 100 * n / sum(n), cpc = cumsum(pc))


nrows <- min(10, nrow(provenance_calls))
r_vec("nb provenance calls", nrows, provenance_calls$n)
r_vec("percent provenance calls", nrows, provenance_calls$pc)
r_vec("cumpercent provenance calls", nrows, provenance_calls$cpc)
```

`r datatable(provenance_calls)`

## Provenance in number of sites

```{r prov_number_sites}
provenance_sites <- E_prov %>% group_by(src_ref) %>%
  summarize(provenance = paste0(sort(unique(provenance)), collapse = "; "), n_provs = n_distinct(provenance)) %>% 
  count(provenance, sort = TRUE) %>% 
  mutate(pc = 100 * n / sum(n), cpc = cumsum(pc))


# To get to 85 %

nrows <- min(14, nrow(provenance_sites))
r_vec("provenance name", nrows, case_when(provenance_sites$provenance == "" ~ "NA", 
                                          provenance_sites$provenance == "$" ~ "\\$",
                                          TRUE ~ provenance_sites$provenance))
r_vec("nb provenance sites", nrows, provenance_sites$n)
r_vec("percent provenance sites", nrows, provenance_sites$pc)
r_vec("cumpercent provenance sites", nrows, provenance_sites$cpc)

```


`r datatable(provenance_sites)`

# All provenances

## By combinations

## In absolute numbers

# Classes


## In number of calls

```{r class_nb_calls}
classes_calls <- E_prov %>% count(ev_class, wt = duplicates, sort = TRUE) %>% 
  mutate(pc = 100 * n / sum(n), cpc = cumsum(pc))

```


## In number of sites

```{r class_nb_sites}
classes_sites <- E_prov %>% group_by(src_ref) %>%
  summarize(ev_class = paste0(sort(unique(ev_class)), collapse = "; "), n_classes = n_distinct(ev_class)) %>% 
  count(ev_class, sort = TRUE) %>% 
  mutate(pc = 100 * n / sum(n), cpc = cumsum(pc))

```

